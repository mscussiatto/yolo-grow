{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Pvt7ExFpd7IA",
        "Yg83QQ-_ezdO"
      ],
      "authorship_tag": "ABX9TyNm0hhEVFuM9t1DYr9AJTw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscussiatto/yolo-grow/blob/main/yolov8n-seg-masks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Drive and Time\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OzQJ_Z8cYvto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y locales\n",
        "!locale-gen en_US.UTF-8\n",
        "!update-locale LANG=en_US.UTF-8\n",
        "!export LANG=en_US.UTF-8\n",
        "!locale -a  # Make sure en_US.UTF-8 is listed"
      ],
      "metadata": {
        "id": "I4g6SkdLMmTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgDsjchBJ_N-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QWzNOhpVoZew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Masks to polygons\n",
        "Create \"labels\" directory in the root of the job folder (CVATs job dataset).\n",
        "\n"
      ],
      "metadata": {
        "id": "YqTWccajLl_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/grow/job_372223-2023_10_27_08_41_57-segmentationmask1.1/SegmentationClass'\n",
        "output_dir = '/content/drive/MyDrive/grow/job_372223-2023_10_27_08_41_57-segmentationmask1.1/labels'\n",
        "\n",
        "for j in os.listdir(input_dir):\n",
        "    image_path = os.path.join(input_dir, j)\n",
        "    # load the binary mask and get its contours\n",
        "    mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    _, mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    H, W = mask.shape\n",
        "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # convert the contours to polygons\n",
        "    polygons = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 200:\n",
        "            polygon = []\n",
        "            for point in cnt:\n",
        "                x, y = point[0]\n",
        "                polygon.append(x / W)\n",
        "                polygon.append(y / H)\n",
        "            polygons.append(polygon)\n",
        "\n",
        "    # print the polygons\n",
        "    with open('{}.txt'.format(os.path.join(output_dir, j)[:-4]), 'w') as f:\n",
        "        for polygon in polygons:\n",
        "            for p_, p in enumerate(polygon):\n",
        "                if p_ == len(polygon) - 1:\n",
        "                    f.write('{}\\n'.format(p))\n",
        "                elif p_ == 0:\n",
        "                    f.write('0 {} '.format(p))\n",
        "                else:\n",
        "                    f.write('{} '.format(p))\n",
        "\n",
        "        f.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NCYfWQRmLuAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train YOLOv8-seg\n",
        "Train semantic segmentation model using custom dataset.\n"
      ],
      "metadata": {
        "id": "Y9FFMQMSTZUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "PXwbgU2rXIJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "model.train(data='/content/drive/MyDrive/grow/config.yaml', epochs=200, imgsz=640)"
      ],
      "metadata": {
        "id": "rBV58whyXKPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Running Inference and saving results/crops\n",
        "Trying to get the RGB mask in the crops."
      ],
      "metadata": {
        "id": "N2JanP5GLcgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "_m90CAdkNO5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normal CLI saving crops and inference results."
      ],
      "metadata": {
        "id": "8vU1_JVMpKD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8n model\n",
        "model = YOLO('/content/drive/MyDrive/grow/models/yolov8n-seg_200e_640p/weights/best.pt')\n",
        "\n",
        "# Run inference on 'bus.jpg' with arguments\n",
        "model.predict('/content/drive/MyDrive/grow/dataset_1/images/test', save=True, save_crop=True, imgsz=640, conf=0.8)"
      ],
      "metadata": {
        "id": "lV4LEvLiMS2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Get all the binary masks saved in one image and individually. same as in binary_mask.py\n",
        "Runs inference, save results and save individual binary masks per inference."
      ],
      "metadata": {
        "id": "-MMuvAKNtiAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Load a pretrained YOLOv8n-seg Segment model\n",
        "model = YOLO('/content/drive/MyDrive/grow/models/yolov8n-seg_200e_640p/weights/best.pt')\n",
        "\n",
        "# Run inference on an image\n",
        "results = model('/content/drive/MyDrive/grow/dataset_1/images/test/2023-10-27_05-54-40.jpeg')  # results list\n",
        "\n",
        "result = results[0]\n",
        "\n",
        "print(result.names)\n",
        "# print(result.boxes.xyxy)\n",
        "# print(result.boxes.conf)\n",
        "# print(result.boxes.cls)\n",
        "# print(result.masks.data)\n",
        "\n",
        "Path(\"./output/\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "cv2.imwrite(f\"./output/original_image.jpg\", result.orig_img)\n",
        "\n",
        "seg_classes = list(result.names.values())\n",
        "# seg_classes = [\"salanova_euler\", \"seedling\", \"empty\", \"radicchio_trevigiano\"]\n",
        "\n",
        "for result in results:\n",
        "\n",
        "    masks = result.masks.data\n",
        "    boxes = result.boxes.data\n",
        "\n",
        "    clss = boxes[:, 5]\n",
        "    print(\"clss\")\n",
        "    print(clss)\n",
        "\n",
        "    #EXTRACT A SINGLE MASK WITH ALL THE CLASSES\n",
        "    obj_indices = torch.where(clss != -1)\n",
        "    obj_masks = masks[obj_indices]\n",
        "    obj_mask = torch.any(obj_masks, dim=0).int() * 255\n",
        "    cv2.imwrite(str(f'./output/all-masks.jpg'), obj_mask.cpu().numpy())\n",
        "\n",
        "    #MASK OF ALL INSTANCES OF A CLASS\n",
        "    for i, seg_class in enumerate(seg_classes):\n",
        "\n",
        "        obj_indices = torch.where(clss == i)\n",
        "        print(\"obj_indices\")\n",
        "        print(obj_indices)\n",
        "        obj_masks = masks[obj_indices]\n",
        "        obj_mask = torch.any(obj_masks, dim=0).int() * 255\n",
        "\n",
        "        cv2.imwrite(str(f'./output/{seg_class}s.jpg'), obj_mask.cpu().numpy())\n",
        "\n",
        "        #MASK FOR EACH INSTANCE OF A CLASS\n",
        "        for i, obj_index in enumerate(obj_indices[0].cpu().numpy()):\n",
        "            obj_masks = masks[torch.tensor([obj_index])]\n",
        "            obj_mask = torch.any(obj_masks, dim=0).int() * 255\n",
        "            cv2.imwrite(str(f'./output/{seg_class}_{i}.jpg'), obj_mask.cpu().numpy())"
      ],
      "metadata": {
        "id": "UeLwV_bN2Ike"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
